{
 "metadata": {
  "name": "",
  "signature": "sha256:0f4868c9b9a1322cf4ebc65b6d7c3e62f4dc6460714c641e2e588cb3e3dbd1e7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "print(sys.version)\n",
      "import pandas as pd\n",
      "import math\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime\n",
      "import bson\n",
      "import gzip\n",
      "import pickle\n",
      "from collections import Counter\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.7.7 |Anaconda 2.0.1 (64-bit)| (default, Jun 11 2014, 10:40:02) [MSC v.1500 64 bit (AMD64)]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "known_influencers = [('Henrique Bastos', '\u200f@henriquebastos', 14227855),\n",
      "('Michael Kennedy', '@mkennedy', 12953262),\n",
      "('Talk Python Podcast', '@TalkPython', 3098427092),\n",
      "('Russel Winder', '@russel_winder', 238541848),\n",
      "('Richard Jones', '\u200f@r1chardj0n3s', 14379613),\n",
      "('Mikko Ohtamaa', '\u200f@moo9000', 50703014),\n",
      "('Tibor Szir\u00e1ki', '@openerphu', 173394343),\n",
      "('Data Science Renee', '\u200f@BecomingDataSci', 2343198944),\n",
      "('steve_piercy', '@steve_piercy', 93713345)]\n",
      "known_influencers_dict = {x[2]:x for x in known_influencers}\n",
      "known_influencers_set = {x[2] for x in known_influencers}\n",
      "def get_known_influencers(df):\n",
      "    return [x for x in df['id'] if x in known_influencers_set]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_list = ['all_texts/' + str(x) for x in pd.read_csv('first_level_sample_list_exists')['0']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using rosetta"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "https://github.com/columbia-applied-data-science/rosetta/blob/master/examples/vw_helpers.md"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rosetta.text.text_processors import BaseTokenizer\n",
      "import rosetta.text.nlp\n",
      "class TokenizerBasic3(BaseTokenizer):\n",
      "    def text_to_token_list(self, text):\n",
      "        tokens = rosetta.text.nlp.word_tokenize(text, L=3, numeric=False)\n",
      "        return [word.lower() for word in tokens if not rosetta.text.nlp.is_stopword(word)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#my_tokenizer.text_to_token_list('werwertrew ty erth tyh rtunjfgn jfyuj rujyfun')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#?TokenizerBasic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rosetta import TextFileStreamer, TokenizerBasic, MakeTokenizer\n",
      "\n",
      "#my_tokenizer = TokenizerBasic()\n",
      "my_tokenizer = TokenizerBasic3()\n",
      "#my_tokenizer = MakeTokenizer(clean)\n",
      "#stream = TextFileStreamer(tokenizer=my_tokenizer, path_list=path_list)#text_base_path \n",
      "stream = TextFileStreamer(tokenizer=my_tokenizer, text_base_path='all_texts') \n",
      "stream.to_vw('doc_tokens_all.vw', n_jobs=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from rosetta import TextFileStreamer, TokenizerBasic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sff.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rosetta.text.text_processors import SFileFilter, VWFormatter\n",
      "sff = SFileFilter(VWFormatter())\n",
      "sff.load_sfile('doc_tokens_all.vw')\n",
      "\n",
      "df = sff.to_frame()\n",
      "df.head()\n",
      "df.describe()\n",
      "\n",
      "sff.filter_extremes(doc_freq_min=5, doc_fraction_max=0.8)\n",
      "sff.compactify()\n",
      "sff.save('sff_file_all.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Removed 820030/977013 tokens\n",
        "Compactification done.  self.bit_precision_required = 18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "collisions = 0, vocab_size = 156983"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "All collisions resolved"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sff.filter_sfile('doc_tokens_all.vw', 'doc_tokens_filtered_all.vw')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter = 0\n",
      "with open('doc_tokens_filtered_all.vw', 'r') as f_in:\n",
      "    with open('doc_tokens_filtered_all_fixed.vw', 'w') as f_out:\n",
      "        for line in f_in:\n",
      "            if line[-3] == '|':\n",
      "                counter += 1\n",
      "            else:\n",
      "                words_count = 0\n",
      "                for x in line.split('|')[1].split(' '):\n",
      "                    words_count += int(x.split(':')[1])\n",
      "                if words_count > \n",
      "                f_out.write(line)\n",
      "                #print(line, file=f_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "1218"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw.exe --lda 20 --cache_file ddrs.cache --passes 10 -p prediction_all.dat --readable_model topics_all.dat --bit_precision 18 doc_tokens_filtered_all_fixed.vw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Num weight bits = 18\n",
        "learning rate = 0.5\n",
        "initial_t = 0\n",
        "power_t = 0.5\n",
        "decay_learning_rate = 1\n",
        "predictions = prediction_all.dat\n",
        "can't open: ddrs.cache, error = No such file or directory\n",
        "creating cache_file = ddrs.cache\n",
        "Reading datafile = doc_tokens_filtered_all_fixed.vw\n",
        "num sources = 1\n",
        "average    since         example     example  current  current  current\n",
        "loss       last          counter      weight    label  predict features\n",
        "13.194272  13.194272         1      1.0     1.0000   0.0000      105\n",
        "13.157826  13.121380         2      2.0     1.0000   0.0000       39\n",
        "13.175115  13.192404         4      4.0     1.0000   0.0000       69\n",
        "12.189789  11.204464         8      8.0     1.0000   0.0000      217\n",
        "11.272938  10.356087        16     16.0     1.0000   0.0000      123\n",
        "10.895573  10.518208        32     32.0     1.0000   0.0000       46\n",
        "10.806581  10.717589        64     64.0     1.0000   0.0000        1\n",
        "10.331567  9.856554        128    128.0     1.0000   0.0000      107\n",
        "10.249196  10.166825       256    256.0     1.0000   0.0000      106\n",
        "10.202064  10.154931       512    512.0     1.0000   0.0000      115\n",
        "10.121961  10.041859      1024   1024.0     1.0000   0.0000        2\n",
        "10.006912  9.891863       2048   2048.0     1.0000   0.0000      129\n",
        "9.912872   9.818832       4096   4096.0     1.0000   0.0000      120\n",
        "9.849909   9.786946       8192   8192.0     1.0000   0.0000       36\n",
        "9.826325   9.802741      16384  16384.0     1.0000   0.0000       90\n",
        "9.699268   9.572210      32768  32768.0     1.0000   0.0000       10\n",
        "9.613219   9.527170      65536  65536.0     1.0000   0.0000      696\n",
        "9.549665   9.486111     131072 131072.0     1.0000   0.0000       90\n",
        "9.637617   9.725570     262144 262144.0     1.0000   0.0000       84\n",
        "9.662667   9.687716     524288 524288.0     1.0000   0.0000       36\n",
        "9.652508   9.642349    1048576 1048576.0     1.0000   0.0000       39\n",
        "\n",
        "finished run\n",
        "number of examples = 1232530\n",
        "weighted example sum = 1.23253e+006\n",
        "weighted label sum = 1.23253e+006\n",
        "average loss = 0 h\n",
        "best constant = 1\n",
        "best constant's loss = 0\n",
        "total feature number = 151825390\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#my_tokenizer('text asd asddasf regtr gtr')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>doc_freq</th>\n",
        "      <th>token_score</th>\n",
        "      <th>doc_fraction</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 284478.000000</td>\n",
        "      <td> 284478.000000</td>\n",
        "      <td> 284478.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>      5.649934</td>\n",
        "      <td>     17.667187</td>\n",
        "      <td>      0.006341</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>     24.026474</td>\n",
        "      <td>    617.944969</td>\n",
        "      <td>      0.026966</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      0.001122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      0.001122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      0.001122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>      2.000000</td>\n",
        "      <td>      3.000000</td>\n",
        "      <td>      0.002245</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    803.000000</td>\n",
        "      <td> 284011.000000</td>\n",
        "      <td>      0.901235</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "            doc_freq    token_score   doc_fraction\n",
        "count  284478.000000  284478.000000  284478.000000\n",
        "mean        5.649934      17.667187       0.006341\n",
        "std        24.026474     617.944969       0.026966\n",
        "min         1.000000       1.000000       0.001122\n",
        "25%         1.000000       1.000000       0.001122\n",
        "50%         1.000000       1.000000       0.001122\n",
        "75%         2.000000       3.000000       0.002245\n",
        "max       803.000000  284011.000000       0.901235"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__slotnames__\n",
        "__module__\n",
        "__doc__\n",
        "__init__\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rosetta.text.vw_helpers import LDAResults\n",
      "import rosetta.text.text_processors\n",
      "num_topics = 20\n",
      "#sff = SFileFilter(VWFormatter())\n",
      "#sff.load_sfile('sff_file.pkl')\n",
      "lda = LDAResults('topics_all.dat', 'prediction_all.dat', sff,\n",
      "                 num_topics=num_topics)\n",
      "lda.print_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "========== Printing top 5 tokens in every topic==========\n",
        "------------------------------\n",
        "Topic name: topic_00.  P[topic_00] = 0.0055\n",
        "                 topic_00  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_01.  P[topic_01] = 0.0478\n",
        "       topic_01  doc_freq\n",
        "token                    \n",
        "die    0.013462      6397\n",
        "van    0.011309      4140\n",
        "een    0.010391      1785\n",
        "het    0.010311      1753\n",
        "der    0.009824      3224\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_02.  P[topic_02] = 0.0055\n",
        "                 topic_02  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_03.  P[topic_03] = 0.0055\n",
        "                 topic_03  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_04.  P[topic_04] = 0.0055\n",
        "                 topic_04  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_05.  P[topic_05] = 0.0055\n",
        "                 topic_05  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_06.  P[topic_06] = 0.0055\n",
        "                 topic_06  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_07.  P[topic_07] = 0.0055\n",
        "                 topic_07  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_08.  P[topic_08] = 0.0055\n",
        "                 topic_08  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_09.  P[topic_09] = 0.0055\n",
        "                 topic_09  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_10.  P[topic_10] = 0.0912\n",
        "         topic_10  doc_freq\n",
        "token                      \n",
        "https    0.595310     99650\n",
        "via      0.019518     37705\n",
        "bir      0.004335      1544\n",
        "&amp     0.003770     41257\n",
        "stories  0.003669      4166\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_11.  P[topic_11] = 0.1233\n",
        "       topic_11  doc_freq\n",
        "token                    \n",
        "http   0.036115     64606\n",
        "que    0.029066     16914\n",
        "para   0.013619     12286\n",
        "por    0.009285     10375\n",
        "con    0.009176     10172\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_12.  P[topic_12] = 0.6490\n",
        "       topic_12  doc_freq\n",
        "token                    \n",
        "http   0.049371     64606\n",
        "new    0.007165     48825\n",
        "out    0.005722     45901\n",
        "&amp   0.005479     41257\n",
        "more   0.004741     37767\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_13.  P[topic_13] = 0.0055\n",
        "                 topic_13  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_14.  P[topic_14] = 0.0055\n",
        "                 topic_14  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_15.  P[topic_15] = 0.0055\n",
        "                 topic_15  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_16.  P[topic_16] = 0.0055\n",
        "                 topic_16  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_17.  P[topic_17] = 0.0055\n",
        "                 topic_17  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_18.  P[topic_18] = 0.0055\n",
        "                 topic_18  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n",
        "\n",
        "------------------------------\n",
        "Topic name: topic_19.  P[topic_19] = 0.0055\n",
        "                 topic_19  doc_freq\n",
        "token                              \n",
        "assalamualaikum  0.000008        30\n",
        "kpmg             0.000007        51\n",
        "siiiii           0.000007        24\n",
        "rocks.           0.000007        10\n",
        "haaaa            0.000006        26\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "?sff.filter_extremes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sff.vocab_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using gensim"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "import nltk\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from string import digits\n",
      "import langid\n",
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "https://github.com/alexperrier/datatalks/blob/master/twitter/twitter_preprocessing.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_lang(lang, documents):\n",
      "    doclang = [  langid.classify(doc[1]) for doc in documents ]\n",
      "    return [documents[k] for k in range(len(documents)) if doclang[k][0] == lang]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "#path_list = ['all_texts/' + str(x) for x in pd.read_csv('first_level_sample_list_exists')['0']]\n",
      "path_list = ['all_texts/' + x for x in os.listdir('all_texts')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycharm_as_followee = np.loadtxt(\"../pycharm_as_followee_p27.txt\")\n",
      "pycharm_as_followee = {int(x) for x in pycharm_as_followee}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_list = ['all_texts/' + x for x in os.listdir('all_texts') if int(x) in pycharm_as_followee]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(path_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "138165"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(pycharm_as_followee)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "12188"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "documents = []\n",
      "for doc_path in path_list:\n",
      "    text = ''\n",
      "    with codecs.open(doc_path, encoding='utf-8') as f:\n",
      "        for line in f:\n",
      "            text += line + ' '\n",
      "    documents.append((doc_path, text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(documents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "138165"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_path = 'subscibers'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  Filter non english documents\n",
      "documents = filter_lang('en', documents)\n",
      "print(\"We have \" + str(len(documents)) + \" documents in english \")\n",
      "\n",
      "# Remove urls\n",
      "documents = [(doc[0], re.sub(r\"(?:\\@|http?\\://)\\S+\", \"\", doc[1]))\n",
      "                for doc in documents ]\n",
      "\n",
      "# Remove documents with less 100 words (some timeline are only composed of URLs)\n",
      "documents = [doc for doc in documents if len(doc[1]) > 100]\n",
      "\n",
      "# tokenize\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "\n",
      "tokenizer = RegexpTokenizer(r'\\w+')\n",
      "documents = [ (doc[0], tokenizer.tokenize(doc[1].lower())) for doc in documents ]\n",
      "\n",
      "# Remove stop words\n",
      "stoplist_tw=['amp','get','got','hey','hmm','hoo','hop','iep','let','ooo','par',\n",
      "            'pdt','pln','pst','wha','yep','yer','aest','didn','nzdt','via',\n",
      "            'one','com','new','like','great','make','top','awesome','best',\n",
      "            'good','wow','yes','say','yay','would','thanks','thank','going',\n",
      "            'new','use','should','could','best','really','see','want','nice',\n",
      "            'while','know']\n",
      "\n",
      "#unigrams = [ w for doc in documents for w in doc if len(w)==1]\n",
      "#bigrams  = [ w for doc in documents for w in doc if len(w)==2]\n",
      "\n",
      "stoplist  = set(nltk.corpus.stopwords.words(\"english\") + stoplist_tw)# + unigrams + bigrams)\n",
      "documents = [(doc[0], [token for token in doc[1] if (token not in stoplist and len(token) > 3)])\n",
      "                for doc in documents]\n",
      "\n",
      "# rm numbers only words\n",
      "documents = [ (doc[0], [token for token in doc[1] if len(token.strip(digits)) == len(token)])\n",
      "                for doc in documents ]\n",
      "\n",
      "# Lammetization\n",
      "# This did not add coherence ot the model and obfuscates interpretability of the\n",
      "# Topics. It was not used in the final model.\n",
      "#   from nltk.stem import WordNetLemmatizer\n",
      "#   lmtzr = WordNetLemmatizer()\n",
      "#   documents=[[lmtzr.lemmatize(token) for token in doc ] for doc in documents]\n",
      "\n",
      "# Remove words that only occur once\n",
      "#token_frequency = defaultdict(int)\n",
      "\n",
      "# count all token\n",
      "# for doc in documents:\n",
      "#     for token in doc:\n",
      "#         token_frequency[token] += 1\n",
      "\n",
      "# keep words that occur more than once\n",
      "# documents = [ [token for token in doc if token_frequency[token] > 1]\n",
      "#                 for doc in documents  ]\n",
      "\n",
      "# Sort words in documents\n",
      "for doc in documents:\n",
      "    doc[1].sort()\n",
      "\n",
      "words_only = [doc[1] for doc in documents]\n",
      "paths_only = [doc[0] for doc in documents]\n",
      "    \n",
      "# Build a dictionary where for each document each word has its own id\n",
      "dictionary = corpora.Dictionary(words_only)\n",
      "dictionary.filter_extremes(no_below=5, no_above=0.8)#, keep_n=100000)\n",
      "dictionary.compactify()\n",
      "# and save the dictionary for future use\n",
      "dictionary.save(target_path + '/corpora.dict')\n",
      "\n",
      "# We now have a dictionary with 26652 unique tokens\n",
      "#print(dictionary)\n",
      "\n",
      "# Build the corpus: vectors with occurence of each word for each document\n",
      "# convert tokenized documents to vectors\n",
      "corpus = [dictionary.doc2bow(doc) for doc in words_only]\n",
      "\n",
      "# and save in Market Matrix format\n",
      "corpora.MmCorpus.serialize(target_path + '/corpora_corpus.mm', corpus)\n",
      "# this corpus can be loaded with corpus = corpora.MmCorpus('alexip_followers.mm')\n",
      "with open(target_path + '/corpus_paths.dat', 'w') as f:\n",
      "    for path in paths_only:\n",
      "        f.write(path + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "We have 6372 documents in english \n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#corpus = [dictionary.doc2bow(' '.join(doc)) for doc in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#documents[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#words_only2 = [[str(x) for x in doc] for doc in words_only]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dictionary = corpora.Dictionary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "#Initialize Parameters\n",
      "corpus_filename = target_path + '/corpora_corpus.mm'\n",
      "dict_filename   = target_path + '/corpora.dict'\n",
      "lda_filename    = target_path + '/corpora.lda'\n",
      "lda_params      = {'num_topics': 40, 'passes': 20, 'alpha': 0.001}\n",
      "\n",
      "#print(\"Corpus of %s documents\" % len(documents))\n",
      "\n",
      "# Load the corpus and Dictionary\n",
      "#corpus = corpora.MmCorpus(corpus_filename)\n",
      "#dictionary = corpora.Dictionary.load(dict_filename)\n",
      "\n",
      "print(\"Running LDA with: %s  \" % lda_params)\n",
      "lda = models.LdaModel(corpus, id2word=dictionary,\n",
      "                        num_topics=lda_params['num_topics'],\n",
      "                        passes=lda_params['passes'],\n",
      "                        alpha = lda_params['alpha'])\n",
      "#print()\n",
      "lda.print_topics()\n",
      "lda.save(lda_filename)\n",
      "print(\"lda saved in %s \" % lda_filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running LDA with: {'passes': 20, 'num_topics': 40, 'alpha': 0.001}  \n",
        "lda saved in subscibers/corpora.lda "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction = np.zeros((len(corpus), lda_params['num_topics']))\n",
      "for doc_i in range(len(corpus)):\n",
      "    doc = corpus[doc_i]\n",
      "    for k,v in lda.get_document_topics(doc):\n",
      "        prediction[doc_i, k] = v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df = pd.DataFrame(prediction, columns=['topic_' + str(x) for x in range(lda_params['num_topics'])], index = [int(x.split('/')[1]) for x in paths_only])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df.to_csv(target_path + '/corpora_predictions.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(path_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "10228"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gensim\n",
      "lda_vw = gensim.models.wrappers.LdaVowpalWabbit('vw.exe',\n",
      "                                                 corpus=corpus,\n",
      "                                                 num_topics=40,\n",
      "                                                 passes=20,\n",
      "                                                 alpha=0.001,\n",
      "                                                 id2word=dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda_vw.save('alexip_vw.lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda_vw.print_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[u'0.030*neo4j + 0.029*nigeria + 0.015*free + 0.011*nigerian + 0.011*africa + 0.010*http + 0.009*america + 0.008*british + 0.008*protest + 0.007*police',\n",
        " u'0.040*djangocon + 0.013*duth + 0.012*auch + 0.011*aber + 0.009*nicht + 0.007*wien + 0.007*dann + 0.006*dass + 0.006*mehr + 0.004*vienna',\n",
        " u'0.021*niet + 0.019*voor + 0.012*maar + 0.009*mijn + 0.008*zijn + 0.008*mysql + 0.006*mongodb + 0.006*naar + 0.006*geen + 0.005*clojure',\n",
        " u'0.019*career + 0.019*jobs + 0.018*tech + 0.016*ireland + 0.014*dublin + 0.014*featuring + 0.012*check + 0.012*looking + 0.010*channel + 0.009*irish',\n",
        " u'0.001*bless + 0.000*christmas + 0.000*think + 0.000*nothing + 0.000*early + 0.000*research + 0.000*mind + 0.000*getting + 0.000*windows + 0.000*times',\n",
        " u'0.070*firefox + 0.052*help + 0.025*sorry + 0.022*tweet + 0.020*might + 0.019*inconvenience + 0.018*query + 0.017*problem + 0.014*using + 0.013*need',\n",
        " u'0.064*neo4j + 0.053*graph + 0.020*meetup + 0.013*cypher + 0.010*michael + 0.009*graphs + 0.009*query + 0.008*graphdb + 0.008*docker + 0.005*nodes',\n",
        " u'0.034*bitcoin + 0.019*security + 0.016*nasa + 0.013*blockchain + 0.006*market + 0.006*malware + 0.005*agora + 0.005*privacy + 0.004*time + 0.004*attack',\n",
        " u'0.078*datascience + 0.050*data + 0.041*science + 0.037*learning + 0.034*python + 0.028*machinelearning + 0.022*bigdata + 0.022*deep + 0.016*machine + 0.014*spark',\n",
        " u'0.113*video + 0.058*playlist + 0.053*added + 0.052*liked + 0.033*india + 0.031*official + 0.017*full + 0.014*song + 0.012*songs + 0.009*music']"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gensim.models.wrappers.ldavowpalwabbit.write_corpus_as_vw(corpus, 'corpus.vw')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "542"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw.exe --lda 40 --minibatch 2000 --cache_file ddrs.cache --passes 20 -p prediction_all.dat --readable_model topics_all.dat --bit_precision 18 corpus.vw"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Num weight bits = 18\n",
        "learning rate = 0.5\n",
        "initial_t = 0\n",
        "power_t = 0.5\n",
        "decay_learning_rate = 1\n",
        "predictions = prediction_all.dat\n",
        "can't open: ddrs.cache, error = No such file or directory\n",
        "creating cache_file = ddrs.cache\n",
        "Reading datafile = corpus.vw\n",
        "num sources = 1\n",
        "average    since         example     example  current  current  current\n",
        "loss       last          counter      weight    label  predict features\n",
        "13.396970  13.396970         1      1.0    unknown   0.0000       55\n",
        "13.412948  13.428926         2      2.0    unknown   0.0000       22\n",
        "12.983844  12.554740         4      4.0    unknown   0.0000     2869\n",
        "11.229764  9.475684          8      8.0    unknown   0.0000      861\n",
        "10.958396  10.687027        16     16.0    unknown   0.0000        8\n",
        "10.617364  10.276332        32     32.0    unknown   0.0000       84\n",
        "10.283157  9.948950         64     64.0    unknown   0.0000      502\n",
        "10.011421  9.739684        128    128.0    unknown   0.0000      510\n",
        "9.828065   9.644709        256    256.0    unknown   0.0000     3398\n",
        "9.711307   9.594549        512    512.0    unknown   0.0000       40\n",
        "9.631405   9.551503       1024   1024.0    unknown   0.0000     4884\n",
        "9.562946   9.494486       2048   2048.0    unknown   0.0000       60\n",
        "9.508503   9.454060       4096   4096.0    unknown   0.0000      139\n",
        "9.462755   9.417007       8192   8192.0    unknown   0.0000     3838\n",
        "\n",
        "finished run\n",
        "number of examples = 9760\n",
        "weighted example sum = 9760\n",
        "weighted label sum = 0\n",
        "average loss = 0 h\n",
        "total feature number = 13942020\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw.exe --lda 40 --minibatch 2000 --cache_file ddrs.cache --passes 20 -p prediction_1000.dat --readable_model topics_1000.dat --bit_precision 18 sample_1000/vw_corpus.dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Num weight bits = 18\n",
        "learning rate = 0.5\n",
        "initial_t = 0\n",
        "power_t = 0.5\n",
        "decay_learning_rate = 1\n",
        "predictions = prediction_1000.dat\n",
        "can't open: ddrs.cache, error = No such file or directory\n",
        "creating cache_file = ddrs.cache\n",
        "Reading datafile = sample_1000/vw_corpus.dat\n",
        "num sources = 1\n",
        "average    since         example     example  current  current  current\n",
        "loss       last          counter      weight    label  predict features\n",
        "13.396970  13.396970         1      1.0    unknown   0.0000       55\n",
        "13.327728  13.258486         2      2.0    unknown   0.0000       22\n",
        "13.394847  13.461967         4      4.0    unknown   0.0000     2869\n",
        "13.425086  13.455324         8      8.0    unknown   0.0000      861\n",
        "14.253229  15.081373        16     16.0    unknown   0.0000        8\n",
        "14.684862  15.116495        32     32.0    unknown   0.0000       84\n",
        "14.922999  15.161135        64     64.0    unknown   0.0000      502\n",
        "14.914793  14.906588       128    128.0    unknown   0.0000      510\n",
        "14.922777  14.930761       256    256.0    unknown   0.0000     3398\n",
        "14.670592  14.418406       512    512.0    unknown   0.0000       40\n",
        "12.060698  9.450804       1024   1024.0    unknown   0.0000     4884\n",
        "10.628462  9.196225       2048   2048.0    unknown   0.0000       60\n",
        "9.825781   9.023100       4096   4096.0    unknown   0.0000      139\n",
        "9.381694   8.937608       8192   8192.0    unknown   0.0000     3838\n",
        "\n",
        "finished run\n",
        "number of examples = 9760\n",
        "weighted example sum = 9760\n",
        "weighted label sum = 0\n",
        "average loss = 0 h\n",
        "total feature number = 13942020\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  Filter non english documents\n",
      "documents = filter_lang('en', documents)\n",
      "print(\"We have \" + str(len(documents)) + \" documents in english \")\n",
      "\n",
      "# Remove urls\n",
      "documents = [(doc[0], re.sub(r\"(?:\\@|http?\\://)\\S+\", \"\", doc[1]))\n",
      "                for doc in documents ]\n",
      "\n",
      "# Remove documents with less 100 words (some timeline are only composed of URLs)\n",
      "documents = [doc for doc in documents if len(doc[1]) > 100]\n",
      "\n",
      "# tokenize\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "\n",
      "tokenizer = RegexpTokenizer(r'\\w+')\n",
      "documents = [ (doc[0], tokenizer.tokenize(doc[1].lower())) for doc in documents ]\n",
      "\n",
      "# Remove stop words\n",
      "stoplist_tw=['amp','get','got','hey','hmm','hoo','hop','iep','let','ooo','par',\n",
      "            'pdt','pln','pst','wha','yep','yer','aest','didn','nzdt','via',\n",
      "            'one','com','new','like','great','make','top','awesome','best',\n",
      "            'good','wow','yes','say','yay','would','thanks','thank','going',\n",
      "            'new','use','should','could','best','really','see','want','nice',\n",
      "            'while','know']\n",
      "\n",
      "#unigrams = [ w for doc in documents for w in doc if len(w)==1]\n",
      "#bigrams  = [ w for doc in documents for w in doc if len(w)==2]\n",
      "\n",
      "stoplist  = set(nltk.corpus.stopwords.words(\"english\") + stoplist_tw)# + unigrams + bigrams)\n",
      "documents = [(doc[0], [token for token in doc[1] if (token not in stoplist and len(token) > 3)])\n",
      "                for doc in documents]\n",
      "\n",
      "# rm numbers only words\n",
      "documents = [ (doc[0], [token for token in doc[1] if len(token.strip(digits)) == len(token)])\n",
      "                for doc in documents ]\n",
      "\n",
      "# Lammetization\n",
      "# This did not add coherence ot the model and obfuscates interpretability of the\n",
      "# Topics. It was not used in the final model.\n",
      "#   from nltk.stem import WordNetLemmatizer\n",
      "#   lmtzr = WordNetLemmatizer()\n",
      "#   documents=[[lmtzr.lemmatize(token) for token in doc ] for doc in documents]\n",
      "\n",
      "# Remove words that only occur once\n",
      "#token_frequency = defaultdict(int)\n",
      "\n",
      "# count all token\n",
      "# for doc in documents:\n",
      "#     for token in doc:\n",
      "#         token_frequency[token] += 1\n",
      "\n",
      "# keep words that occur more than once\n",
      "# documents = [ [token for token in doc if token_frequency[token] > 1]\n",
      "#                 for doc in documents  ]\n",
      "\n",
      "# Sort words in documents\n",
      "for doc in documents:\n",
      "    doc[1].sort()\n",
      "\n",
      "words_only = [doc[1] for doc in documents]\n",
      "paths_only = [doc[0] for doc in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "We have 87931 documents in english \n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction = np.zeros((len(words_only), lda_params['num_topics']))\n",
      "for doc_i in range(len(words_only)):\n",
      "    doc = words_only[doc_i]\n",
      "    for k,v in lda.get_document_topics(dictionary.doc2bow(doc)):\n",
      "        prediction[doc_i, k] = v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df = pd.DataFrame(prediction, columns=['topic_' + str(x) for x in range(lda_params['num_topics'])], index = [int(x.split('/')[1]) for x in paths_only])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df.to_csv('predictions_all_from_subscribers.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>topic_0</th>\n",
        "      <th>topic_1</th>\n",
        "      <th>topic_2</th>\n",
        "      <th>topic_3</th>\n",
        "      <th>topic_4</th>\n",
        "      <th>topic_5</th>\n",
        "      <th>topic_6</th>\n",
        "      <th>topic_7</th>\n",
        "      <th>topic_8</th>\n",
        "      <th>topic_9</th>\n",
        "      <th>...</th>\n",
        "      <th>topic_30</th>\n",
        "      <th>topic_31</th>\n",
        "      <th>topic_32</th>\n",
        "      <th>topic_33</th>\n",
        "      <th>topic_34</th>\n",
        "      <th>topic_35</th>\n",
        "      <th>topic_36</th>\n",
        "      <th>topic_37</th>\n",
        "      <th>topic_38</th>\n",
        "      <th>topic_39</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>10000162  </th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.077614</td>\n",
        "      <td> 0.046653</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.029538</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.158019</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10000432  </th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.086923</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.152437</td>\n",
        "      <td> 0.182295</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.093935</td>\n",
        "      <td> 0.022488</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>100012004 </th>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025000</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.025</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1000501502</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.158957</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.054265</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.013890</td>\n",
        "      <td> 0.022256</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>100052009 </th>\n",
        "      <td> 0.031657</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.016817</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.020852</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 40 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "             topic_0   topic_1   topic_2  topic_3  topic_4  topic_5   topic_6  \\\n",
        "10000162    0.000000  0.077614  0.046653    0.000    0.000    0.000  0.000000   \n",
        "10000432    0.000000  0.086923  0.000000    0.000    0.000    0.000  0.152437   \n",
        "100012004   0.025000  0.025000  0.025000    0.025    0.025    0.025  0.025000   \n",
        "1000501502  0.000000  0.158957  0.000000    0.000    0.000    0.000  0.054265   \n",
        "100052009   0.031657  0.000000  0.016817    0.000    0.000    0.000  0.000000   \n",
        "\n",
        "             topic_7  topic_8  topic_9   ...     topic_30  topic_31  topic_32  \\\n",
        "10000162    0.000000    0.000    0.000   ...        0.000     0.000     0.000   \n",
        "10000432    0.182295    0.000    0.000   ...        0.000     0.000     0.000   \n",
        "100012004   0.025000    0.025    0.025   ...        0.025     0.025     0.025   \n",
        "1000501502  0.000000    0.000    0.000   ...        0.000     0.000     0.000   \n",
        "100052009   0.000000    0.000    0.000   ...        0.000     0.000     0.000   \n",
        "\n",
        "            topic_33  topic_34  topic_35  topic_36  topic_37  topic_38  \\\n",
        "10000162       0.000  0.029538  0.000000  0.158019     0.000     0.000   \n",
        "10000432       0.000  0.000000  0.093935  0.022488     0.000     0.000   \n",
        "100012004      0.025  0.025000  0.025000  0.025000     0.025     0.025   \n",
        "1000501502     0.000  0.013890  0.022256  0.000000     0.000     0.000   \n",
        "100052009      0.000  0.020852  0.000000  0.000000     0.000     0.000   \n",
        "\n",
        "            topic_39  \n",
        "10000162       0.000  \n",
        "10000432       0.000  \n",
        "100012004      0.025  \n",
        "1000501502     0.000  \n",
        "100052009      0.000  \n",
        "\n",
        "[5 rows x 40 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df = pd.read_csv('predictions_all_from_subscribers.csv', index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accounts_df = pd.read_csv('../accounts_info.csv', index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#accounts_df.index = accounts_df['id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#accounts_df['followers_count'] = [float(x) for x in accounts_df['followers_count']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_path = 'subscibers'\n",
      "corpus = corpora.MmCorpus(target_path + '/corpora_corpus.mm')\n",
      "dictionary = corpora.Dictionary.load(target_path + '/corpora.dict')\n",
      "lda = models.LdaModel.load(target_path + '/corpora.lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(read_tweets(2705821142))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 317,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(read_tweets(981663991))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Warn', 981663991)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 316,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "def read_tweets(user_id):\n",
      "    info_path = 'all_retweet_counts/' + str(user_id)\n",
      "    text_path = 'all_texts/' + str(user_id)\n",
      "    infos = []\n",
      "    with codecs.open(info_path, encoding='utf-8') as f:\n",
      "        for line in f:\n",
      "            id, retweet_count, favorite_count, lines = line.split('\\t')\n",
      "            infos.append((int(id), int(retweet_count), int(favorite_count), int(lines)))\n",
      "    documents = []\n",
      "    #print(len(infos))\n",
      "    with codecs.open(text_path, encoding='utf-8') as f:\n",
      "        i = 0\n",
      "        text = ''\n",
      "        cur_lines = 1\n",
      "        for line in f:\n",
      "            text += line + ' '\n",
      "            cur_lines += 1\n",
      "            if i == len(infos):\n",
      "                print('Warn', user_id)\n",
      "                break\n",
      "            if infos[i][3] < cur_lines:\n",
      "                documents.append((infos[i], text))\n",
      "                i += 1\n",
      "                text = ''\n",
      "                cur_lines = 1\n",
      "    return documents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess_tweets(documents):\n",
      "    documents = filter_lang('en', documents)\n",
      "    #print(\"We have \" + str(len(documents)) + \" documents in english \")\n",
      "\n",
      "    # Remove urls\n",
      "    documents = [(doc[0], re.sub(r\"(?:\\@|http?\\://)\\S+\", \"\", doc[1]))\n",
      "                    for doc in documents ]\n",
      "\n",
      "    tokenizer = RegexpTokenizer(r'\\w+')\n",
      "    documents = [ (doc[0], tokenizer.tokenize(doc[1].lower())) for doc in documents ]\n",
      "\n",
      "    # Remove stop words\n",
      "    stoplist_tw=['amp','get','got','hey','hmm','hoo','hop','iep','let','ooo','par',\n",
      "                'pdt','pln','pst','wha','yep','yer','aest','didn','nzdt','via',\n",
      "                'one','com','new','like','great','make','top','awesome','best',\n",
      "                'good','wow','yes','say','yay','would','thanks','thank','going',\n",
      "                'new','use','should','could','best','really','see','want','nice',\n",
      "                'while','know']\n",
      "\n",
      "    stoplist  = set(nltk.corpus.stopwords.words(\"english\") + stoplist_tw)# + unigrams + bigrams)\n",
      "    documents = [(doc[0], [token for token in doc[1] if (token not in stoplist and len(token) > 3)])\n",
      "                    for doc in documents]\n",
      "\n",
      "    # rm numbers only words\n",
      "    documents = [ (doc[0], [token for token in doc[1] if len(token.strip(digits)) == len(token)])\n",
      "                    for doc in documents ]\n",
      "\n",
      "    for doc in documents:\n",
      "        doc[1].sort()\n",
      "    \n",
      "    words_only = [doc[1] for doc in documents]\n",
      "    info_only = [doc[0] for doc in documents]\n",
      "    \n",
      "    return (info_only, words_only)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accounts_df.ix[known_influencers_set]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id.1</th>\n",
        "      <th>screen_name</th>\n",
        "      <th>tweets_per_month</th>\n",
        "      <th>retweet_counts</th>\n",
        "      <th>downloaded_tweet_counts</th>\n",
        "      <th>retweet_percent</th>\n",
        "      <th>created_at</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>followers/friends</th>\n",
        "      <th>lang</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>verified</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2343198944</th>\n",
        "      <td> 2343198944</td>\n",
        "      <td> BecomingDataSci</td>\n",
        "      <td> 20</td>\n",
        "      <td>  2</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.10</td>\n",
        "      <td> Fri Feb 14 07:05:57 +0000 2014</td>\n",
        "      <td> 2482</td>\n",
        "      <td> 5207</td>\n",
        "      <td> 3124</td>\n",
        "      <td> 1.666560</td>\n",
        "      <td>  en</td>\n",
        "      <td> 482</td>\n",
        "      <td> 11099</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>93713345  </th>\n",
        "      <td>   93713345</td>\n",
        "      <td>    steve_piercy</td>\n",
        "      <td> 20</td>\n",
        "      <td>  9</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.45</td>\n",
        "      <td> Mon Nov 30 21:29:34 +0000 2009</td>\n",
        "      <td>   47</td>\n",
        "      <td>  179</td>\n",
        "      <td>  128</td>\n",
        "      <td> 1.395349</td>\n",
        "      <td>  en</td>\n",
        "      <td>  21</td>\n",
        "      <td>  1787</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50703014  </th>\n",
        "      <td>   50703014</td>\n",
        "      <td>         moo9000</td>\n",
        "      <td> 20</td>\n",
        "      <td>  4</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.20</td>\n",
        "      <td> Thu Jun 25 17:09:10 +0000 2009</td>\n",
        "      <td> 3182</td>\n",
        "      <td> 1722</td>\n",
        "      <td> 1437</td>\n",
        "      <td> 1.198192</td>\n",
        "      <td>  en</td>\n",
        "      <td> 225</td>\n",
        "      <td>  6984</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>173394343 </th>\n",
        "      <td>  173394343</td>\n",
        "      <td>       openerphu</td>\n",
        "      <td> 60</td>\n",
        "      <td>  2</td>\n",
        "      <td> 200</td>\n",
        "      <td> 0.01</td>\n",
        "      <td> Sun Aug 01 10:18:53 +0000 2010</td>\n",
        "      <td>   19</td>\n",
        "      <td>  139</td>\n",
        "      <td>   65</td>\n",
        "      <td> 2.121212</td>\n",
        "      <td>  hu</td>\n",
        "      <td>   5</td>\n",
        "      <td>  1735</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12953262  </th>\n",
        "      <td>   12953262</td>\n",
        "      <td>        mkennedy</td>\n",
        "      <td> 20</td>\n",
        "      <td> 11</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.55</td>\n",
        "      <td> Fri Feb 01 18:18:08 +0000 2008</td>\n",
        "      <td>  433</td>\n",
        "      <td> 3924</td>\n",
        "      <td> 2125</td>\n",
        "      <td> 1.846190</td>\n",
        "      <td>  en</td>\n",
        "      <td> 239</td>\n",
        "      <td>  4735</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14227855  </th>\n",
        "      <td>   14227855</td>\n",
        "      <td>  henriquebastos</td>\n",
        "      <td> 20</td>\n",
        "      <td> 11</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.55</td>\n",
        "      <td> Wed Mar 26 17:38:25 +0000 2008</td>\n",
        "      <td> 1775</td>\n",
        "      <td> 5314</td>\n",
        "      <td> 1737</td>\n",
        "      <td> 3.058113</td>\n",
        "      <td>  pt</td>\n",
        "      <td> 326</td>\n",
        "      <td> 12248</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3098427092</th>\n",
        "      <td> 3098427092</td>\n",
        "      <td>      TalkPython</td>\n",
        "      <td> 20</td>\n",
        "      <td>  4</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.20</td>\n",
        "      <td> Thu Mar 19 23:06:15 +0000 2015</td>\n",
        "      <td>  885</td>\n",
        "      <td> 4383</td>\n",
        "      <td> 1434</td>\n",
        "      <td> 3.055052</td>\n",
        "      <td>  en</td>\n",
        "      <td> 197</td>\n",
        "      <td>  2312</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>238541848 </th>\n",
        "      <td>  238541848</td>\n",
        "      <td>   russel_winder</td>\n",
        "      <td> 20</td>\n",
        "      <td> 16</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.80</td>\n",
        "      <td> Sat Jan 15 12:14:57 +0000 2011</td>\n",
        "      <td>    9</td>\n",
        "      <td> 1509</td>\n",
        "      <td>  578</td>\n",
        "      <td> 2.607945</td>\n",
        "      <td>  en</td>\n",
        "      <td> 152</td>\n",
        "      <td> 19926</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14379613  </th>\n",
        "      <td>        NaN</td>\n",
        "      <td>             NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>                            NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "                  id.1      screen_name  tweets_per_month  retweet_counts  \\\n",
        "2343198944  2343198944  BecomingDataSci                20               2   \n",
        "93713345      93713345     steve_piercy                20               9   \n",
        "50703014      50703014          moo9000                20               4   \n",
        "173394343    173394343        openerphu                60               2   \n",
        "12953262      12953262         mkennedy                20              11   \n",
        "14227855      14227855   henriquebastos                20              11   \n",
        "3098427092  3098427092       TalkPython                20               4   \n",
        "238541848    238541848    russel_winder                20              16   \n",
        "14379613           NaN              NaN               NaN             NaN   \n",
        "\n",
        "            downloaded_tweet_counts  retweet_percent  \\\n",
        "2343198944                       20             0.10   \n",
        "93713345                         20             0.45   \n",
        "50703014                         20             0.20   \n",
        "173394343                       200             0.01   \n",
        "12953262                         20             0.55   \n",
        "14227855                         20             0.55   \n",
        "3098427092                       20             0.20   \n",
        "238541848                        20             0.80   \n",
        "14379613                        NaN              NaN   \n",
        "\n",
        "                                created_at  favourites_count  followers_count  \\\n",
        "2343198944  Fri Feb 14 07:05:57 +0000 2014              2482             5207   \n",
        "93713345    Mon Nov 30 21:29:34 +0000 2009                47              179   \n",
        "50703014    Thu Jun 25 17:09:10 +0000 2009              3182             1722   \n",
        "173394343   Sun Aug 01 10:18:53 +0000 2010                19              139   \n",
        "12953262    Fri Feb 01 18:18:08 +0000 2008               433             3924   \n",
        "14227855    Wed Mar 26 17:38:25 +0000 2008              1775             5314   \n",
        "3098427092  Thu Mar 19 23:06:15 +0000 2015               885             4383   \n",
        "238541848   Sat Jan 15 12:14:57 +0000 2011                 9             1509   \n",
        "14379613                               NaN               NaN              NaN   \n",
        "\n",
        "            friends_count  followers/friends lang  listed_count  \\\n",
        "2343198944           3124           1.666560   en           482   \n",
        "93713345              128           1.395349   en            21   \n",
        "50703014             1437           1.198192   en           225   \n",
        "173394343              65           2.121212   hu             5   \n",
        "12953262             2125           1.846190   en           239   \n",
        "14227855             1737           3.058113   pt           326   \n",
        "3098427092           1434           3.055052   en           197   \n",
        "238541848             578           2.607945   en           152   \n",
        "14379613              NaN                NaN  NaN           NaN   \n",
        "\n",
        "            statuses_count verified  \n",
        "2343198944           11099    False  \n",
        "93713345              1787    False  \n",
        "50703014              6984    False  \n",
        "173394343             1735    False  \n",
        "12953262              4735    False  \n",
        "14227855             12248    False  \n",
        "3098427092            2312    False  \n",
        "238541848            19926    False  \n",
        "14379613               NaN      NaN  "
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Go for it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theme_threshold = 0.3\n",
      "tweets_per_month_low_bound = 10\n",
      "tweets_per_month_high_bound = 150\n",
      "followers_friends_low_bound = 0.1\n",
      "followers_friends_high_bound = 100\n",
      "followers_low_bound = 200\n",
      "interested_topics = {1, 7, 8, 13}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df[prediction_df['topic_1'] > theme_threshold].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(12364, 40)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df[prediction_df['topic_7'] > theme_threshold].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(545, 40)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df[prediction_df['topic_8'] > theme_threshold].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(36, 40)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_df[prediction_df['topic_13'] > theme_threshold].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(132, 40)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts = set(prediction_df[prediction_df['topic_13'] > theme_threshold].index) | set(prediction_df[prediction_df['topic_8'] > theme_threshold].index) | set(prediction_df[prediction_df['topic_7'] > theme_threshold].index) | set(prediction_df[prediction_df['topic_1'] > theme_threshold].index)\n",
      "len(interesting_accounts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "12869"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts & known_influencers_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "set()"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = accounts_df.ix[[int(x) for x in interesting_accounts]]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(12869, 15)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = interesting_accounts_df[interesting_accounts_df['tweets_per_month'] > tweets_per_month_low_bound]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(6758, 15)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = interesting_accounts_df[interesting_accounts_df['tweets_per_month'] < tweets_per_month_high_bound]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(6539, 15)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = interesting_accounts_df[interesting_accounts_df['followers/friends'] > followers_friends_low_bound]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "(6491, 15)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = interesting_accounts_df[interesting_accounts_df['followers/friends'] < followers_friends_high_bound]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(6486, 15)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df = interesting_accounts_df[interesting_accounts_df['followers_count'] > followers_low_bound]\n",
      "interesting_accounts_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "(5653, 15)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df[interesting_accounts_df['downloaded_tweet_counts'] > 100].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(301, 15)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "wtf??"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users_tweets = dict()\n",
      "for x in interesting_accounts_df.index:\n",
      "    #print(x)\n",
      "    users_tweets[x] = preprocess_tweets(read_tweets(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Warn', 981663991)\n",
        "('Warn', 113019315)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 434408534)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 3233780100)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 845681408)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 2899022680)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 24908823)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 16979571)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 713110741696585728)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 2521001863)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 2895094386)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 2437323589)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 543696180)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 1713417312)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 3114610490)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 5550862)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 14301121)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 324421084)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 2872493866)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 3037504225)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 23942466)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 19290520)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 76074799)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 4853882308)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 4003331722)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Warn', 374505456)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interested_topics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "{1, 7, 8, 13}"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users_topics = dict()\n",
      "for k, v in users_tweets.items():\n",
      "    topics = []\n",
      "    users_topics[k] = topics\n",
      "    for doc in v[1]:\n",
      "        topics.append(lda.get_document_topics(dictionary.doc2bow(doc)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_mean_retweets_in_topic = []\n",
      "user_mean_favorites_in_topic = []\n",
      "tweets_in_topic = []\n",
      "for x in interesting_accounts_df.index:\n",
      "    retweets_in_topic = []\n",
      "    favorites_in_topic = []\n",
      "    topics_tweets = users_topics[x]\n",
      "    for i in range(len(topics_tweets)):\n",
      "        topics = topics_tweets[i]\n",
      "        for k, v in topics:\n",
      "            if k in interested_topics and v > 0.6:\n",
      "                #print(k, v)\n",
      "                retweets_in_topic.append(users_tweets[x][0][i][1])\n",
      "                favorites_in_topic.append(users_tweets[x][0][i][2])\n",
      "                break\n",
      "    user_mean_retweets_in_topic.append(np.mean(retweets_in_topic))\n",
      "    user_mean_favorites_in_topic.append(np.mean(favorites_in_topic))\n",
      "    tweets_in_topic.append(len(favorites_in_topic))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df['mean_retweets_in_topic'] = [0 if np.isnan(x) else x for x in user_mean_retweets_in_topic]\n",
      "interesting_accounts_df['mean_favorites_in_topic'] = [0 if np.isnan(x) else x for x in user_mean_favorites_in_topic]\n",
      "interesting_accounts_df['tweets_in_topic'] = tweets_in_topic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df[interesting_accounts_df['tweets_in_topic'] > 0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "(5518, 18)"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_level_sample_list = path_list = [int(x) for x in pd.read_csv('first_level_sample_list_exists')['0']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accounts_from_first_level = set(first_level_sample_list) & set(interesting_accounts_df[interesting_accounts_df['tweets_in_topic'] > 0].index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df.ix[accounts_from_first_level]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id.1</th>\n",
        "      <th>screen_name</th>\n",
        "      <th>tweets_per_month</th>\n",
        "      <th>retweet_counts</th>\n",
        "      <th>downloaded_tweet_counts</th>\n",
        "      <th>retweet_percent</th>\n",
        "      <th>created_at</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>followers/friends</th>\n",
        "      <th>lang</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>verified</th>\n",
        "      <th>mean_retweets_in_topic</th>\n",
        "      <th>mean_favorites_in_topic</th>\n",
        "      <th>tweets_in_topic</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>3187132960</th>\n",
        "      <td> 3187132960</td>\n",
        "      <td>     pyquantnews</td>\n",
        "      <td> 124</td>\n",
        "      <td>  164</td>\n",
        "      <td>  412</td>\n",
        "      <td> 0.398058</td>\n",
        "      <td> Mon Apr 20 12:55:10 +0000 2015</td>\n",
        "      <td>     8</td>\n",
        "      <td>   456</td>\n",
        "      <td>   953</td>\n",
        "      <td>  0.479036</td>\n",
        "      <td> en</td>\n",
        "      <td>   54</td>\n",
        "      <td>    352</td>\n",
        "      <td> False</td>\n",
        "      <td>  5.955128</td>\n",
        "      <td>  1.108974</td>\n",
        "      <td> 156</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>340394880 </th>\n",
        "      <td>  340394880</td>\n",
        "      <td> CareerZootweets</td>\n",
        "      <td>  60</td>\n",
        "      <td> 1013</td>\n",
        "      <td> 3247</td>\n",
        "      <td> 0.311980</td>\n",
        "      <td> Fri Jul 22 16:43:30 +0000 2011</td>\n",
        "      <td>  1568</td>\n",
        "      <td>  3734</td>\n",
        "      <td>  2021</td>\n",
        "      <td>  1.847181</td>\n",
        "      <td> en</td>\n",
        "      <td>  104</td>\n",
        "      <td>   3878</td>\n",
        "      <td> False</td>\n",
        "      <td>  3.332677</td>\n",
        "      <td>  0.600394</td>\n",
        "      <td> 508</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14159138  </th>\n",
        "      <td>   14159138</td>\n",
        "      <td>        raymondh</td>\n",
        "      <td>  20</td>\n",
        "      <td>    1</td>\n",
        "      <td>   20</td>\n",
        "      <td> 0.050000</td>\n",
        "      <td> Sun Mar 16 20:12:52 +0000 2008</td>\n",
        "      <td>    43</td>\n",
        "      <td> 20003</td>\n",
        "      <td>   251</td>\n",
        "      <td> 79.380952</td>\n",
        "      <td> en</td>\n",
        "      <td>  886</td>\n",
        "      <td>   1876</td>\n",
        "      <td> False</td>\n",
        "      <td> 35.000000</td>\n",
        "      <td> 69.500000</td>\n",
        "      <td>   6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7626052   </th>\n",
        "      <td>    7626052</td>\n",
        "      <td>           __ads</td>\n",
        "      <td>  22</td>\n",
        "      <td>   39</td>\n",
        "      <td>  757</td>\n",
        "      <td> 0.051519</td>\n",
        "      <td> Sat Jul 21 07:15:44 +0000 2007</td>\n",
        "      <td>     5</td>\n",
        "      <td>   297</td>\n",
        "      <td>  1232</td>\n",
        "      <td>  0.241687</td>\n",
        "      <td> en</td>\n",
        "      <td>   28</td>\n",
        "      <td>    698</td>\n",
        "      <td> False</td>\n",
        "      <td>  0.637363</td>\n",
        "      <td>  0.098901</td>\n",
        "      <td>  91</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3179083369</th>\n",
        "      <td> 3179083369</td>\n",
        "      <td>       spericorn</td>\n",
        "      <td>  98</td>\n",
        "      <td>    0</td>\n",
        "      <td>  127</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Wed Apr 29 07:15:24 +0000 2015</td>\n",
        "      <td>     0</td>\n",
        "      <td>   222</td>\n",
        "      <td>  1615</td>\n",
        "      <td>  0.137995</td>\n",
        "      <td> en</td>\n",
        "      <td>    1</td>\n",
        "      <td>     67</td>\n",
        "      <td> False</td>\n",
        "      <td>  0.015625</td>\n",
        "      <td>  0.453125</td>\n",
        "      <td>  64</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12861132  </th>\n",
        "      <td>   12861132</td>\n",
        "      <td>   AnaLuciaNovak</td>\n",
        "      <td>  20</td>\n",
        "      <td>    3</td>\n",
        "      <td>   20</td>\n",
        "      <td> 0.150000</td>\n",
        "      <td> Wed Jan 30 04:24:57 +0000 2008</td>\n",
        "      <td> 31238</td>\n",
        "      <td> 27119</td>\n",
        "      <td> 21567</td>\n",
        "      <td>  1.257418</td>\n",
        "      <td> en</td>\n",
        "      <td> 2024</td>\n",
        "      <td> 130864</td>\n",
        "      <td> False</td>\n",
        "      <td>  1.333333</td>\n",
        "      <td>  0.333333</td>\n",
        "      <td>   3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2931191885</th>\n",
        "      <td> 2931191885</td>\n",
        "      <td>        NRGchain</td>\n",
        "      <td>  20</td>\n",
        "      <td>   19</td>\n",
        "      <td>   20</td>\n",
        "      <td> 0.950000</td>\n",
        "      <td> Fri Dec 19 00:44:24 +0000 2014</td>\n",
        "      <td>     7</td>\n",
        "      <td> 38191</td>\n",
        "      <td> 21646</td>\n",
        "      <td>  1.764309</td>\n",
        "      <td> en</td>\n",
        "      <td>  135</td>\n",
        "      <td>    568</td>\n",
        "      <td> False</td>\n",
        "      <td>  2.428571</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td>   7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4847340819</th>\n",
        "      <td> 4847340819</td>\n",
        "      <td>        getpaysa</td>\n",
        "      <td>  76</td>\n",
        "      <td>   16</td>\n",
        "      <td>   97</td>\n",
        "      <td> 0.164948</td>\n",
        "      <td> Tue Jan 26 00:00:56 +0000 2016</td>\n",
        "      <td>   647</td>\n",
        "      <td>   310</td>\n",
        "      <td>   653</td>\n",
        "      <td>  0.475535</td>\n",
        "      <td> en</td>\n",
        "      <td>    8</td>\n",
        "      <td>     77</td>\n",
        "      <td> False</td>\n",
        "      <td>  1.838710</td>\n",
        "      <td>  0.741935</td>\n",
        "      <td>  31</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2894675102</th>\n",
        "      <td> 2894675102</td>\n",
        "      <td>  DailyTechVideo</td>\n",
        "      <td>  12</td>\n",
        "      <td>    0</td>\n",
        "      <td>  519</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Sun Nov 09 11:41:57 +0000 2014</td>\n",
        "      <td>     1</td>\n",
        "      <td>   289</td>\n",
        "      <td>   370</td>\n",
        "      <td>  0.781671</td>\n",
        "      <td> en</td>\n",
        "      <td>   79</td>\n",
        "      <td>    459</td>\n",
        "      <td> False</td>\n",
        "      <td>  0.383333</td>\n",
        "      <td>  0.450000</td>\n",
        "      <td>  60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2899022680</th>\n",
        "      <td> 2899022680</td>\n",
        "      <td>        dirkzitt</td>\n",
        "      <td>  62</td>\n",
        "      <td>  150</td>\n",
        "      <td>  198</td>\n",
        "      <td> 0.757576</td>\n",
        "      <td> Sun Nov 30 10:16:20 +0000 2014</td>\n",
        "      <td>    14</td>\n",
        "      <td>   411</td>\n",
        "      <td>  1047</td>\n",
        "      <td>  0.393130</td>\n",
        "      <td> de</td>\n",
        "      <td>   46</td>\n",
        "      <td>    162</td>\n",
        "      <td> False</td>\n",
        "      <td> 29.960396</td>\n",
        "      <td>  0.178218</td>\n",
        "      <td> 101</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16067035  </th>\n",
        "      <td>   16067035</td>\n",
        "      <td>         ogrisel</td>\n",
        "      <td>  20</td>\n",
        "      <td>   13</td>\n",
        "      <td>   20</td>\n",
        "      <td> 0.650000</td>\n",
        "      <td> Sun Aug 31 14:51:19 +0000 2008</td>\n",
        "      <td>   801</td>\n",
        "      <td> 14090</td>\n",
        "      <td>  1452</td>\n",
        "      <td>  9.697866</td>\n",
        "      <td> en</td>\n",
        "      <td> 1026</td>\n",
        "      <td>   9689</td>\n",
        "      <td> False</td>\n",
        "      <td> 11.333333</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td>   6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1656046686</th>\n",
        "      <td> 1656046686</td>\n",
        "      <td>  wro_consulting</td>\n",
        "      <td>  15</td>\n",
        "      <td>  765</td>\n",
        "      <td> 1484</td>\n",
        "      <td> 0.515499</td>\n",
        "      <td> Thu Aug 08 19:47:11 +0000 2013</td>\n",
        "      <td>   230</td>\n",
        "      <td>   606</td>\n",
        "      <td>  1995</td>\n",
        "      <td>  0.304108</td>\n",
        "      <td> pt</td>\n",
        "      <td>   17</td>\n",
        "      <td>   1453</td>\n",
        "      <td> False</td>\n",
        "      <td> 15.846890</td>\n",
        "      <td>  0.129187</td>\n",
        "      <td> 209</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17518751  </th>\n",
        "      <td>   17518751</td>\n",
        "      <td>       klunkySQL</td>\n",
        "      <td>  20</td>\n",
        "      <td>   20</td>\n",
        "      <td>   20</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> Thu Nov 20 19:05:50 +0000 2008</td>\n",
        "      <td> 12458</td>\n",
        "      <td> 18474</td>\n",
        "      <td> 17098</td>\n",
        "      <td>  1.080473</td>\n",
        "      <td> en</td>\n",
        "      <td>  404</td>\n",
        "      <td>  12889</td>\n",
        "      <td> False</td>\n",
        "      <td> 16.714286</td>\n",
        "      <td>  0.000000</td>\n",
        "      <td>   7</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "                  id.1      screen_name  tweets_per_month  retweet_counts  \\\n",
        "3187132960  3187132960      pyquantnews               124             164   \n",
        "340394880    340394880  CareerZootweets                60            1013   \n",
        "14159138      14159138         raymondh                20               1   \n",
        "7626052        7626052            __ads                22              39   \n",
        "3179083369  3179083369        spericorn                98               0   \n",
        "12861132      12861132    AnaLuciaNovak                20               3   \n",
        "2931191885  2931191885         NRGchain                20              19   \n",
        "4847340819  4847340819         getpaysa                76              16   \n",
        "2894675102  2894675102   DailyTechVideo                12               0   \n",
        "2899022680  2899022680         dirkzitt                62             150   \n",
        "16067035      16067035          ogrisel                20              13   \n",
        "1656046686  1656046686   wro_consulting                15             765   \n",
        "17518751      17518751        klunkySQL                20              20   \n",
        "\n",
        "            downloaded_tweet_counts  retweet_percent  \\\n",
        "3187132960                      412         0.398058   \n",
        "340394880                      3247         0.311980   \n",
        "14159138                         20         0.050000   \n",
        "7626052                         757         0.051519   \n",
        "3179083369                      127         0.000000   \n",
        "12861132                         20         0.150000   \n",
        "2931191885                       20         0.950000   \n",
        "4847340819                       97         0.164948   \n",
        "2894675102                      519         0.000000   \n",
        "2899022680                      198         0.757576   \n",
        "16067035                         20         0.650000   \n",
        "1656046686                     1484         0.515499   \n",
        "17518751                         20         1.000000   \n",
        "\n",
        "                                created_at  favourites_count  followers_count  \\\n",
        "3187132960  Mon Apr 20 12:55:10 +0000 2015                 8              456   \n",
        "340394880   Fri Jul 22 16:43:30 +0000 2011              1568             3734   \n",
        "14159138    Sun Mar 16 20:12:52 +0000 2008                43            20003   \n",
        "7626052     Sat Jul 21 07:15:44 +0000 2007                 5              297   \n",
        "3179083369  Wed Apr 29 07:15:24 +0000 2015                 0              222   \n",
        "12861132    Wed Jan 30 04:24:57 +0000 2008             31238            27119   \n",
        "2931191885  Fri Dec 19 00:44:24 +0000 2014                 7            38191   \n",
        "4847340819  Tue Jan 26 00:00:56 +0000 2016               647              310   \n",
        "2894675102  Sun Nov 09 11:41:57 +0000 2014                 1              289   \n",
        "2899022680  Sun Nov 30 10:16:20 +0000 2014                14              411   \n",
        "16067035    Sun Aug 31 14:51:19 +0000 2008               801            14090   \n",
        "1656046686  Thu Aug 08 19:47:11 +0000 2013               230              606   \n",
        "17518751    Thu Nov 20 19:05:50 +0000 2008             12458            18474   \n",
        "\n",
        "            friends_count  followers/friends lang  listed_count  \\\n",
        "3187132960            953           0.479036   en            54   \n",
        "340394880            2021           1.847181   en           104   \n",
        "14159138              251          79.380952   en           886   \n",
        "7626052              1232           0.241687   en            28   \n",
        "3179083369           1615           0.137995   en             1   \n",
        "12861132            21567           1.257418   en          2024   \n",
        "2931191885          21646           1.764309   en           135   \n",
        "4847340819            653           0.475535   en             8   \n",
        "2894675102            370           0.781671   en            79   \n",
        "2899022680           1047           0.393130   de            46   \n",
        "16067035             1452           9.697866   en          1026   \n",
        "1656046686           1995           0.304108   pt            17   \n",
        "17518751            17098           1.080473   en           404   \n",
        "\n",
        "            statuses_count verified  mean_retweets_in_topic  \\\n",
        "3187132960             352    False                5.955128   \n",
        "340394880             3878    False                3.332677   \n",
        "14159138              1876    False               35.000000   \n",
        "7626052                698    False                0.637363   \n",
        "3179083369              67    False                0.015625   \n",
        "12861132            130864    False                1.333333   \n",
        "2931191885             568    False                2.428571   \n",
        "4847340819              77    False                1.838710   \n",
        "2894675102             459    False                0.383333   \n",
        "2899022680             162    False               29.960396   \n",
        "16067035              9689    False               11.333333   \n",
        "1656046686            1453    False               15.846890   \n",
        "17518751             12889    False               16.714286   \n",
        "\n",
        "            mean_favorites_in_topic  tweets_in_topic  \n",
        "3187132960                 1.108974              156  \n",
        "340394880                  0.600394              508  \n",
        "14159138                  69.500000                6  \n",
        "7626052                    0.098901               91  \n",
        "3179083369                 0.453125               64  \n",
        "12861132                   0.333333                3  \n",
        "2931191885                 0.000000                7  \n",
        "4847340819                 0.741935               31  \n",
        "2894675102                 0.450000               60  \n",
        "2899022680                 0.178218              101  \n",
        "16067035                   0.000000                6  \n",
        "1656046686                 0.129187              209  \n",
        "17518751                   0.000000                7  "
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#interesting_accounts_df.ix[known_influencers_set]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting_accounts_df[interesting_accounts_df['tweets_in_topic'] > 10].sort('mean_favorites_in_topic').tail(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id.1</th>\n",
        "      <th>screen_name</th>\n",
        "      <th>tweets_per_month</th>\n",
        "      <th>retweet_counts</th>\n",
        "      <th>downloaded_tweet_counts</th>\n",
        "      <th>retweet_percent</th>\n",
        "      <th>created_at</th>\n",
        "      <th>favourites_count</th>\n",
        "      <th>followers_count</th>\n",
        "      <th>friends_count</th>\n",
        "      <th>followers/friends</th>\n",
        "      <th>lang</th>\n",
        "      <th>listed_count</th>\n",
        "      <th>statuses_count</th>\n",
        "      <th>verified</th>\n",
        "      <th>mean_retweets_in_topic</th>\n",
        "      <th>mean_favorites_in_topic</th>\n",
        "      <th>tweets_in_topic</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>18185124  </th>\n",
        "      <td>   18185124</td>\n",
        "      <td>    jeffbullas</td>\n",
        "      <td>  20</td>\n",
        "      <td>  0</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Wed Dec 17 07:53:23 +0000 2008</td>\n",
        "      <td>  2011</td>\n",
        "      <td> 453734</td>\n",
        "      <td> 298939</td>\n",
        "      <td>  1.517813</td>\n",
        "      <td> en</td>\n",
        "      <td> 22624</td>\n",
        "      <td> 249542</td>\n",
        "      <td> False</td>\n",
        "      <td> 16.500000</td>\n",
        "      <td>  8.714286</td>\n",
        "      <td> 14</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2790795553</th>\n",
        "      <td> 2790795553</td>\n",
        "      <td>    datawallow</td>\n",
        "      <td>  11</td>\n",
        "      <td> 26</td>\n",
        "      <td>  77</td>\n",
        "      <td> 0.337662</td>\n",
        "      <td> Thu Sep 04 22:58:47 +0000 2014</td>\n",
        "      <td> 51917</td>\n",
        "      <td>   7660</td>\n",
        "      <td>   7238</td>\n",
        "      <td>  1.058295</td>\n",
        "      <td> en</td>\n",
        "      <td>   158</td>\n",
        "      <td>     76</td>\n",
        "      <td> False</td>\n",
        "      <td> 13.678571</td>\n",
        "      <td>  9.000000</td>\n",
        "      <td> 28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15231287  </th>\n",
        "      <td>   15231287</td>\n",
        "      <td>   Gartner_inc</td>\n",
        "      <td>  20</td>\n",
        "      <td>  1</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.050000</td>\n",
        "      <td> Wed Jun 25 14:03:20 +0000 2008</td>\n",
        "      <td>  1636</td>\n",
        "      <td> 315422</td>\n",
        "      <td>  46567</td>\n",
        "      <td>  6.773385</td>\n",
        "      <td> en</td>\n",
        "      <td>  9874</td>\n",
        "      <td>  15946</td>\n",
        "      <td> False</td>\n",
        "      <td> 15.272727</td>\n",
        "      <td>  9.000000</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>168826960 </th>\n",
        "      <td>  168826960</td>\n",
        "      <td>   AWSstartups</td>\n",
        "      <td> 104</td>\n",
        "      <td> 54</td>\n",
        "      <td> 199</td>\n",
        "      <td> 0.271357</td>\n",
        "      <td> Tue Jul 20 22:08:31 +0000 2010</td>\n",
        "      <td>   188</td>\n",
        "      <td>  81115</td>\n",
        "      <td>   2578</td>\n",
        "      <td> 31.452501</td>\n",
        "      <td> en</td>\n",
        "      <td>  1129</td>\n",
        "      <td>   4312</td>\n",
        "      <td> False</td>\n",
        "      <td> 33.424242</td>\n",
        "      <td> 10.166667</td>\n",
        "      <td> 66</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>454219112 </th>\n",
        "      <td>  454219112</td>\n",
        "      <td>      SAPCloud</td>\n",
        "      <td>  20</td>\n",
        "      <td>  0</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Tue Jan 03 19:10:19 +0000 2012</td>\n",
        "      <td>  6214</td>\n",
        "      <td>  32507</td>\n",
        "      <td>   7581</td>\n",
        "      <td>  4.287523</td>\n",
        "      <td> en</td>\n",
        "      <td>   506</td>\n",
        "      <td>   8931</td>\n",
        "      <td> False</td>\n",
        "      <td> 21.181818</td>\n",
        "      <td> 14.545455</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>287049865 </th>\n",
        "      <td>  287049865</td>\n",
        "      <td>   SQLPerfTips</td>\n",
        "      <td> 101</td>\n",
        "      <td> 22</td>\n",
        "      <td> 200</td>\n",
        "      <td> 0.110000</td>\n",
        "      <td> Sun Apr 24 06:36:45 +0000 2011</td>\n",
        "      <td>   149</td>\n",
        "      <td>  51588</td>\n",
        "      <td>   6885</td>\n",
        "      <td>  7.491868</td>\n",
        "      <td> en</td>\n",
        "      <td>  1345</td>\n",
        "      <td>   3967</td>\n",
        "      <td> False</td>\n",
        "      <td> 12.000000</td>\n",
        "      <td> 14.861111</td>\n",
        "      <td> 36</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>60126900  </th>\n",
        "      <td>   60126900</td>\n",
        "      <td>  alexfeist_de</td>\n",
        "      <td>  11</td>\n",
        "      <td>  0</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Sat Jul 25 19:17:54 +0000 2009</td>\n",
        "      <td>   658</td>\n",
        "      <td>  29983</td>\n",
        "      <td>  23419</td>\n",
        "      <td>  1.280273</td>\n",
        "      <td> en</td>\n",
        "      <td>   686</td>\n",
        "      <td>    758</td>\n",
        "      <td> False</td>\n",
        "      <td>  6.181818</td>\n",
        "      <td> 18.909091</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2230478545</th>\n",
        "      <td> 2230478545</td>\n",
        "      <td> Strong_Social</td>\n",
        "      <td>  20</td>\n",
        "      <td>  3</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.150000</td>\n",
        "      <td> Wed Dec 04 20:49:15 +0000 2013</td>\n",
        "      <td>  1040</td>\n",
        "      <td> 101300</td>\n",
        "      <td>  60464</td>\n",
        "      <td>  1.675366</td>\n",
        "      <td> en</td>\n",
        "      <td>  1792</td>\n",
        "      <td>  16772</td>\n",
        "      <td> False</td>\n",
        "      <td> 22.461538</td>\n",
        "      <td> 20.384615</td>\n",
        "      <td> 13</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>331659804 </th>\n",
        "      <td>  331659804</td>\n",
        "      <td>     MikeTamir</td>\n",
        "      <td>  20</td>\n",
        "      <td>  0</td>\n",
        "      <td>  20</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Fri Jul 08 14:36:16 +0000 2011</td>\n",
        "      <td>   255</td>\n",
        "      <td>   6567</td>\n",
        "      <td>   4228</td>\n",
        "      <td>  1.553086</td>\n",
        "      <td> en</td>\n",
        "      <td>   392</td>\n",
        "      <td>   1758</td>\n",
        "      <td> False</td>\n",
        "      <td> 15.090909</td>\n",
        "      <td> 21.909091</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2325351036</th>\n",
        "      <td> 2325351036</td>\n",
        "      <td>   cayenneapps</td>\n",
        "      <td> 132</td>\n",
        "      <td>  0</td>\n",
        "      <td> 200</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> Mon Feb 03 11:58:24 +0000 2014</td>\n",
        "      <td>  2447</td>\n",
        "      <td>  29848</td>\n",
        "      <td>  26407</td>\n",
        "      <td>  1.130301</td>\n",
        "      <td> en</td>\n",
        "      <td>   685</td>\n",
        "      <td>   1873</td>\n",
        "      <td> False</td>\n",
        "      <td> 19.591837</td>\n",
        "      <td> 22.387755</td>\n",
        "      <td> 49</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "                  id.1    screen_name  tweets_per_month  retweet_counts  \\\n",
        "id                                                                        \n",
        "18185124      18185124     jeffbullas                20               0   \n",
        "2790795553  2790795553     datawallow                11              26   \n",
        "15231287      15231287    Gartner_inc                20               1   \n",
        "168826960    168826960    AWSstartups               104              54   \n",
        "454219112    454219112       SAPCloud                20               0   \n",
        "287049865    287049865    SQLPerfTips               101              22   \n",
        "60126900      60126900   alexfeist_de                11               0   \n",
        "2230478545  2230478545  Strong_Social                20               3   \n",
        "331659804    331659804      MikeTamir                20               0   \n",
        "2325351036  2325351036    cayenneapps               132               0   \n",
        "\n",
        "            downloaded_tweet_counts  retweet_percent  \\\n",
        "id                                                     \n",
        "18185124                         20         0.000000   \n",
        "2790795553                       77         0.337662   \n",
        "15231287                         20         0.050000   \n",
        "168826960                       199         0.271357   \n",
        "454219112                        20         0.000000   \n",
        "287049865                       200         0.110000   \n",
        "60126900                         20         0.000000   \n",
        "2230478545                       20         0.150000   \n",
        "331659804                        20         0.000000   \n",
        "2325351036                      200         0.000000   \n",
        "\n",
        "                                created_at  favourites_count  followers_count  \\\n",
        "id                                                                              \n",
        "18185124    Wed Dec 17 07:53:23 +0000 2008              2011           453734   \n",
        "2790795553  Thu Sep 04 22:58:47 +0000 2014             51917             7660   \n",
        "15231287    Wed Jun 25 14:03:20 +0000 2008              1636           315422   \n",
        "168826960   Tue Jul 20 22:08:31 +0000 2010               188            81115   \n",
        "454219112   Tue Jan 03 19:10:19 +0000 2012              6214            32507   \n",
        "287049865   Sun Apr 24 06:36:45 +0000 2011               149            51588   \n",
        "60126900    Sat Jul 25 19:17:54 +0000 2009               658            29983   \n",
        "2230478545  Wed Dec 04 20:49:15 +0000 2013              1040           101300   \n",
        "331659804   Fri Jul 08 14:36:16 +0000 2011               255             6567   \n",
        "2325351036  Mon Feb 03 11:58:24 +0000 2014              2447            29848   \n",
        "\n",
        "            friends_count  followers/friends lang  listed_count  \\\n",
        "id                                                                \n",
        "18185124           298939           1.517813   en         22624   \n",
        "2790795553           7238           1.058295   en           158   \n",
        "15231287            46567           6.773385   en          9874   \n",
        "168826960            2578          31.452501   en          1129   \n",
        "454219112            7581           4.287523   en           506   \n",
        "287049865            6885           7.491868   en          1345   \n",
        "60126900            23419           1.280273   en           686   \n",
        "2230478545          60464           1.675366   en          1792   \n",
        "331659804            4228           1.553086   en           392   \n",
        "2325351036          26407           1.130301   en           685   \n",
        "\n",
        "            statuses_count verified  mean_retweets_in_topic  \\\n",
        "id                                                            \n",
        "18185124            249542    False               16.500000   \n",
        "2790795553              76    False               13.678571   \n",
        "15231287             15946    False               15.272727   \n",
        "168826960             4312    False               33.424242   \n",
        "454219112             8931    False               21.181818   \n",
        "287049865             3967    False               12.000000   \n",
        "60126900               758    False                6.181818   \n",
        "2230478545           16772    False               22.461538   \n",
        "331659804             1758    False               15.090909   \n",
        "2325351036            1873    False               19.591837   \n",
        "\n",
        "            mean_favorites_in_topic  tweets_in_topic  \n",
        "id                                                    \n",
        "18185124                   8.714286               14  \n",
        "2790795553                 9.000000               28  \n",
        "15231287                   9.000000               11  \n",
        "168826960                 10.166667               66  \n",
        "454219112                 14.545455               11  \n",
        "287049865                 14.861111               36  \n",
        "60126900                  18.909091               11  \n",
        "2230478545                20.384615               13  \n",
        "331659804                 21.909091               11  \n",
        "2325351036                22.387755               49  "
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min(user_mean_retweets_in_topic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_mean_retweets_in_topic[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[0, 0, 0, 0, 0, 0, 0, 0]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users_tweets[981663991][0]#[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[(722868607227547648L, 0, 0, 1),\n",
        " (722860555606753280L, 0, 0, 1),\n",
        " (722814363090837504L, 0, 0, 1),\n",
        " (722810404070490112L, 0, 1, 1),\n",
        " (722795381130547200L, 0, 0, 1),\n",
        " (722788773906362369L, 0, 0, 1),\n",
        " (722565877447700480L, 0, 0, 1),\n",
        " (722563292078698496L, 0, 0, 1),\n",
        " (722528487752339456L, 0, 0, 1),\n",
        " (722505253640388608L, 0, 0, 1),\n",
        " (722498181167259648L, 0, 1, 1),\n",
        " (722487316023873537L, 0, 1, 1),\n",
        " (722448031904370688L, 0, 0, 1),\n",
        " (722443812187017216L, 0, 0, 1),\n",
        " (722436722974461952L, 0, 1, 1),\n",
        " (722200892397760512L, 0, 0, 1),\n",
        " (722143078614601728L, 0, 0, 1)]"
       ]
      }
     ],
     "prompt_number": 40
    }
   ],
   "metadata": {}
  }
 ]
}